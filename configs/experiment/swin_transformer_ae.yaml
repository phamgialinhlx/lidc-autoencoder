# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vq_gan_3d


defaults:
  - override /data: lidc_2d
  - override /model: swin_transformer_ae
  - override /callbacks: autoencoder2d
  - override /trainer: default
  - override /logger: wandb

tags: ["autoencoder", "vqgan_2d", "lidc2d"]
task_name: "train_autoencoder"

data:
#   data_dir: "/data/hpc/pgl/LIDC-IDRI-2D/data/"
  batch_size: 24
#   image_size: 128
#   train_val_test_split: [80, 10, 10]
#   nodules_only: True
#   include_mask: False
#   include_origin_image: False
#   include_segmentation: True
#   num_workers: 4
#   pin_memory: False

model:
  encoderconfig:
    feature_size: 48
  autoencoderconfig:
    channel_multipliers: [1, 2, 4]
  loss: 
    _target_: src.models.components.vq_gan_2d.losses.vqperceptual.VQLPIPSWithDiscriminator
    disc_start: 20000
    codebook_weight: 1.0
    disc_num_layers: 2
    disc_in_channels: 1
    disc_weight: 0.6
    disc_conditional: false
    n_classes: 1

logger: 
  wandb:
    name: "swin_transformer_ae"
    id: 8felsmbh

callbacks:
  log_image:
    frequency: 1
    seg_head: True
  log_metrics:
    seg_head: True
  model_checkpoint:
    monitor: "val/ssim"
    mode: "max"
    save_last: True

trainer:
  max_epochs: 1000

ckpt_path: "/work/hpc/pgl/lung-diffusion/logs/train_autoencoder/runs/2024-04-30_11-22-23/checkpoints/epoch_003.ckpt"
