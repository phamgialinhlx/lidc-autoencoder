# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vq_gan_3d


defaults:
  - override /data: lidc_2d
  - override /model: downstream_segmentation_2d
  - override /callbacks: segmentation2d
  - override /trainer: default
  - override /logger: wandb

tags: ["segmentation", "lidc"]
task_name: "train_segmentation"

data:
#   data_dir: "/data/hpc/pgl/LIDC-IDRI-2D/data/"
  batch_size: 64
  include_clean: True
#   image_size: 128
#   train_val_test_split: [80, 10, 10]
#   nodules_only: True
#   include_mask: True
#   include_origin_image: False
#   include_segmentation: True
#   num_workers: 4
#   pin_memory: False

model:
  net:
    # _target_: src.models.components.segmentation.encoder_swin_unetr.SwinUNETR
    # img_size: 128
    # in_channels: 1
    # out_channels: 2
    # spatial_dims: 2
    # feature_size: 48
    _target_: src.models.components.monai.swin_unetr.SwinUNETR
    img_size: 128
    in_channels: 1
    out_channels: 2
    spatial_dims: 2
    feature_size: 48
    use_checkpoint: true

  autoencoder_path: "/work/hpc/pgl/lung-diffusion/outputs/swin_transformer_ae_f48/checkpoints/epoch_036.ckpt"
  criterion:
    _target_: src.models.components.loss_function.cross_entropy.CrossEntropyLoss
    # weight: [1.0, 1.0]
    weight: [1.0, 50.0]

  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 0.0001
    weight_decay: 0.0

  use_ema: True

logger: 
  wandb:
    name: "ds_unetr_ema"
    # id: 3aaj48q0

callbacks:
  model_checkpoint:
    monitor: "val/dice"
    mode: "max"
    save_last: True
    
trainer:
  max_epochs: 1000
  accelerator: gpu

# ckpt_path: "/work/hpc/pgl/lung-diffusion/logs/train_segmentation/runs/2024-05-02_12-32-05/lung-thesis/3aaj48q0/checkpoints/epoch=26-step=7020.ckpt"
ckpt_path: "/work/hpc/pgl/lung-diffusion/logs/train_segmentation/runs/2024-05-05_10-05-09/lung-thesis/1wonkpjw/checkpoints/epoch=99-step=26000.ckpt"
