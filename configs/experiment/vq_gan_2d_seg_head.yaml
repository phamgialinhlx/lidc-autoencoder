# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vq_gan_3d


defaults:
  - override /data: lidc2d
  - override /model: vq_gan_2d_seg_head
  - override /callbacks: autoencoder2d
  - override /trainer: default
  - override /logger: wandb

tags: ["autoencoder", "vqgan_2d", "lidc2d"]
task_name: "train_autoencoder"

data:
  data_dir: "/data/hpc/pgl/LIDC-IDRI-2D/data/"
  batch_size: 8
  image_size: 128
  train_val_test_split: [80, 10, 10]
  nodules_only: True
  include_mask: False
  include_segmentation: True
  num_workers: 4
  pin_memory: False

model:
  loss: 
    _target_: src.models.components.vq_gan_2d.losses.vqperceptual.VQLPIPSWithDiscriminator
    disc_start: 1
    codebook_weight: 1.0
    disc_num_layers: 2
    disc_in_channels: 1
    disc_weight: 0.6
    disc_conditional: false
    n_classes: 1

  autoencoderconfig:
    channels: 128
    channel_multipliers: [1, 1, 2, 4]
    n_resnet_blocks: 2
    img_channels: 1
    z_channels: 16
    double_z: False
    resolution: 128
    attn_resolutions:
    - 16
    out_img_size: 16
    out_channels: 16

logger: 
  wandb:
    name: "vq_gan_2d_seg_head"

callbacks:
  log_image:
    frequency: 1
    seg_head: True
  log_metrics:
    seg_head: True

trainer:
  max_epochs: 1000
