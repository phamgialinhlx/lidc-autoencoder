# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vq_gan_3d


defaults:
  - override /data: lidc_2d
  - override /model: multihead_swin_transformer_ae
  - override /callbacks: autoencoder2d
  - override /trainer: default
  - override /logger: wandb

tags: ["autoencoder", "vqgan_2d", "lidc2d"]
task_name: "train_autoencoder"

# data:
#   data_dir: "/data/hpc/pgl/LIDC-IDRI-2D/data/"
#   batch_size: 16
#   image_size: 128
#   train_val_test_split: [80, 10, 10]
#   nodules_only: True
#   include_mask: False
#   include_origin_image: False
#   include_segmentation: True
#   num_workers: 4
#   pin_memory: False

model:
  autoencoderconfig:
    channel_multipliers: [1, 2, 4]
  segmentation_decoder:
    _target_: src.models.components.segmentation.encoder_swin_unetr.SwinUNETR
    img_size: 128
    in_channels: 1
    out_channels: 2
    use_checkpoint: True
    spatial_dims: 2

  segmentation_criterion: 
    _target_: src.models.components.loss_function.cross_entropy.CrossEntropyLoss
    weight: [1.0, 25.0]

logger: 
  wandb:
    name: "multihead_swin_transformer_ae"

callbacks:
  log_image:
    frequency: 1
    seg_head: True
  log_metrics:
    seg_head: True
  model_checkpoint:
    monitor: "val/ssim"
    mode: "max"
    save_last: True

trainer:
  max_epochs: 1000
