# @package _global_

# to execute this experiment run:
# python src/train.py experiment=vq_gan_3d


defaults:
  - override /data: lidc
  # - override /model: vq_gan_3d
  - override /model: multihead_vq_gan_3d
  # - override /callbacks: autoencoder
  - override /callbacks: multihead_ae
  - override /trainer: default
  - override /logger: wandb

tags: ["autoencoder", "vqgan_3d", "multihead", "lidc"]
task_name: "train autoencoder"

model:
  n_hiddens: 32
  use_ema: True
  downsample: [4, 4, 4]
  # segmentation_decoder: !!null
  # classifier_head: !!null
  segmentation_decoder:
    _target_: src.models.components.segmentation.encoder_unet3d.EncoderUNet3D
    n_channels: 1
    n_classes: 2
    base_channel: 32
  classifier_head:
    _target_: src.models.components.classification.resnet3d_head.ResNet3DHead
    num_blocks: [1, 1]
    num_channels: 128
    num_classes: 2
  
data:
  train_val_test_split: [80, 10, 10]
  augmentation: False
  image_size: 128
  batch_size: 1

logger: 
  wandb:
    name: "multihead_autoencoder"

callbacks:
  metrics_logger:
    ssim: 
      _target_: pytorch_msssim.SSIM
      data_range: 1
      size_average: True
      channel: 1
    msssim: 
      _target_: pytorch_msssim.MS_SSIM
      data_range: 1 
      size_average: True
      channel: 1
      win_size: 3
      
  model_checkpoint:
    monitor: "val/msssim"
    mode: "max"
    save_last: True
    
trainer:
  max_epochs: 1000
  # precision: 16-mixed
